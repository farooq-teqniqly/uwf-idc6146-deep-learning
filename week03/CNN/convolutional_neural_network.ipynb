{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: download tensorflow and pillow first"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T19:00:49.143930Z",
     "start_time": "2024-09-06T18:59:07.847713Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tensorflow",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.0-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading rich-13.8.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n",
      "   ---------------------------------------- 0.0/385.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 8.7/385.2 MB 48.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 19.9/385.2 MB 52.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 31.5/385.2 MB 53.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 42.2/385.2 MB 52.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 53.5/385.2 MB 53.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 64.7/385.2 MB 53.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 76.3/385.2 MB 54.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 89.4/385.2 MB 55.4 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 100.4/385.2 MB 54.8 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 111.9/385.2 MB 39.3 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 116.4/385.2 MB 38.1 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 121.6/385.2 MB 37.3 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 126.4/385.2 MB 36.5 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 131.3/385.2 MB 35.7 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 136.8/385.2 MB 35.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 142.1/385.2 MB 34.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 147.3/385.2 MB 34.3 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 152.6/385.2 MB 34.0 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 157.8/385.2 MB 33.6 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 163.3/385.2 MB 33.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 168.6/385.2 MB 33.0 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 174.1/385.2 MB 32.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 179.6/385.2 MB 32.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 184.3/385.2 MB 32.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 189.8/385.2 MB 32.0 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 195.0/385.2 MB 31.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 200.5/385.2 MB 31.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 205.0/385.2 MB 31.3 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 210.2/385.2 MB 31.1 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 215.0/385.2 MB 30.9 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 219.4/385.2 MB 30.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 224.1/385.2 MB 30.4 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 228.6/385.2 MB 30.1 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 233.3/385.2 MB 29.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 238.3/385.2 MB 29.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 243.5/385.2 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 248.3/385.2 MB 29.5 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 253.0/385.2 MB 29.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 258.5/385.2 MB 29.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 263.7/385.2 MB 29.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 269.0/385.2 MB 28.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 274.5/385.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 279.7/385.2 MB 28.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 285.2/385.2 MB 27.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 290.5/385.2 MB 27.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 295.7/385.2 MB 27.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 301.2/385.2 MB 26.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 306.2/385.2 MB 26.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 311.4/385.2 MB 26.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 316.7/385.2 MB 26.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 322.2/385.2 MB 25.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 327.4/385.2 MB 25.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 332.9/385.2 MB 25.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 338.2/385.2 MB 24.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.4/385.2 MB 24.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 348.7/385.2 MB 24.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.9/385.2 MB 24.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 359.4/385.2 MB 23.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 364.4/385.2 MB 23.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.4/385.2 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.6/385.2 MB 25.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.1/385.2 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.2/385.2 MB 23.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.5/26.4 MB 22.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.7/26.4 MB 24.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 25.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 26.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 25.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.0-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 5.0/15.5 MB 27.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.5/15.5 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 26.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 25.1 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------------------- - 5.2/5.5 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 23.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp312-cp312-win_amd64.whl (267 kB)\n",
      "Downloading rich-13.8.0-py3-none-any.whl (241 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, typing-extensions, termcolor, tensorboard-data-server, protobuf, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, optree, opt-einsum, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.0\n",
      "    Uninstalling numpy-2.1.0:\n",
      "      Successfully uninstalled numpy-2.1.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 rich-13.8.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 termcolor-2.4.0 typing-extensions-4.12.2 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:01:34.103003Z",
     "start_time": "2024-09-06T19:01:18.150123Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:01:39.373389Z",
     "start_time": "2024-09-06T19:01:39.365305Z"
    }
   },
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0koUcJMJpEBD"
   },
   "outputs": [],
   "source": [
    "# to avoid overfitting \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,  #feature scaling to all pixels to [0,1]\n",
    "                                   shear_range = 0.2, #transformations\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', #path\n",
    "                                                 target_size = (64, 64), #training size\n",
    "                                                 batch_size = 32,        #images taking each time\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SH4WzfOhpKc3"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "#colored image in RGB, it's 64x64 as defined above, so it's 64x64x3\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) #pool_size is the dimension of pooling matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) # input shape is deleted\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) #number of hidden neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #binary output for cats or dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUj1W4PJptta"
   },
   "outputs": [],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog' \n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED9KB3I54c1i"
   },
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
