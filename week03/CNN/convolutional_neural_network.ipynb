{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: download tensorflow and pillow first"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T19:00:49.143930Z",
     "start_time": "2024-09-06T18:59:07.847713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from win32console import FOREGROUND_GREEN, FOREGROUND_RED\n",
    "!pip install tensorflow"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.0-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading rich-13.8.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n",
      "   ---------------------------------------- 0.0/385.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 8.7/385.2 MB 48.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 19.9/385.2 MB 52.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 31.5/385.2 MB 53.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 42.2/385.2 MB 52.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 53.5/385.2 MB 53.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 64.7/385.2 MB 53.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 76.3/385.2 MB 54.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 89.4/385.2 MB 55.4 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 100.4/385.2 MB 54.8 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 109.6/385.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 111.9/385.2 MB 39.3 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 116.4/385.2 MB 38.1 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 121.6/385.2 MB 37.3 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 126.4/385.2 MB 36.5 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 131.3/385.2 MB 35.7 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 136.8/385.2 MB 35.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 142.1/385.2 MB 34.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 147.3/385.2 MB 34.3 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 152.6/385.2 MB 34.0 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 157.8/385.2 MB 33.6 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 163.3/385.2 MB 33.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 168.6/385.2 MB 33.0 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 174.1/385.2 MB 32.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 179.6/385.2 MB 32.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 184.3/385.2 MB 32.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 189.8/385.2 MB 32.0 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 195.0/385.2 MB 31.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 200.5/385.2 MB 31.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 205.0/385.2 MB 31.3 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 210.2/385.2 MB 31.1 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 215.0/385.2 MB 30.9 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 219.4/385.2 MB 30.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 224.1/385.2 MB 30.4 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 228.6/385.2 MB 30.1 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 233.3/385.2 MB 29.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 238.3/385.2 MB 29.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 243.5/385.2 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 248.3/385.2 MB 29.5 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 253.0/385.2 MB 29.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 258.5/385.2 MB 29.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 263.7/385.2 MB 29.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 269.0/385.2 MB 28.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 274.5/385.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 279.7/385.2 MB 28.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 285.2/385.2 MB 27.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 290.5/385.2 MB 27.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 295.7/385.2 MB 27.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 301.2/385.2 MB 26.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 306.2/385.2 MB 26.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 311.4/385.2 MB 26.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 316.7/385.2 MB 26.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 322.2/385.2 MB 25.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 327.4/385.2 MB 25.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 332.9/385.2 MB 25.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 338.2/385.2 MB 24.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.4/385.2 MB 24.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 348.7/385.2 MB 24.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.9/385.2 MB 24.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 359.4/385.2 MB 23.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 364.4/385.2 MB 23.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.4/385.2 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.6/385.2 MB 25.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.1/385.2 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.2/385.2 MB 23.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.5/26.4 MB 22.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.7/26.4 MB 24.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 25.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 26.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 25.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.0-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 5.0/15.5 MB 27.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.5/15.5 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 26.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 25.1 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------------------- - 5.2/5.5 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 23.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp312-cp312-win_amd64.whl (267 kB)\n",
      "Downloading rich-13.8.0-py3-none-any.whl (241 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, typing-extensions, termcolor, tensorboard-data-server, protobuf, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, optree, opt-einsum, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.0\n",
      "    Uninstalling numpy-2.1.0:\n",
      "      Successfully uninstalled numpy-2.1.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 rich-13.8.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 termcolor-2.4.0 typing-extensions-4.12.2 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T19:09:36.904505Z",
     "start_time": "2024-09-06T19:09:19.976443Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install scipy",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 5.0/44.5 MB 30.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.9/44.5 MB 42.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 26.2/44.5 MB 46.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.2/44.5 MB 47.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 45.7 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.14.1\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:01:34.103003Z",
     "start_time": "2024-09-06T19:01:18.150123Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:01:39.373389Z",
     "start_time": "2024-09-06T19:01:39.365305Z"
    }
   },
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0koUcJMJpEBD",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:04:20.225462Z",
     "start_time": "2024-09-06T19:04:20.095572Z"
    }
   },
   "source": [
    "# to avoid overfitting \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,  #feature scaling to all pixels to [0,1]\n",
    "                                   shear_range = 0.2, #transformations\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', #path\n",
    "                                                 target_size = (64, 64), #training size\n",
    "                                                 batch_size = 32,        #images taking each time\n",
    "                                                 class_mode = 'binary')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SH4WzfOhpKc3",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:04:28.543691Z",
     "start_time": "2024-09-06T19:04:28.493898Z"
    }
   },
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAUt4UMPlhLS",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:04:38.817904Z",
     "start_time": "2024-09-06T19:04:38.806235Z"
    }
   },
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPzPrMckl-hV",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:06:00.546987Z",
     "start_time": "2024-09-06T19:06:00.467974Z"
    }
   },
   "source": [
    "#colored image in RGB, it's 64x64 as defined above, so it's 64x64x3\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\src\\my\\uwf-idc6146-deep-learning\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncpqPl69mOac",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:06:46.926572Z",
     "start_time": "2024-09-06T19:06:46.916725Z"
    }
   },
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) #pool_size is the dimension of pooling matrix"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_-FZjn_m8gk",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:07:17.971893Z",
     "start_time": "2024-09-06T19:07:17.958103Z"
    }
   },
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) # input shape is deleted\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AZeOGCvnNZn",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:07:24.878113Z",
     "start_time": "2024-09-06T19:07:24.869712Z"
    }
   },
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GtmUlLd26Nq",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:07:44.696518Z",
     "start_time": "2024-09-06T19:07:44.671276Z"
    }
   },
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) #number of hidden neurons"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p_Zj1Mc3Ko_",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:07:47.487559Z",
     "start_time": "2024-09-06T19:07:47.470361Z"
    }
   },
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #binary output for cats or dogs"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NALksrNQpUlJ",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:08:26.225688Z",
     "start_time": "2024-09-06T19:08:26.212034Z"
    }
   },
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUj1W4PJptta",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:19:05.483316Z",
     "start_time": "2024-09-06T19:09:45.130689Z"
    }
   },
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\src\\my\\uwf-idc6146-deep-learning\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 130ms/step - accuracy: 0.5438 - loss: 0.6885 - val_accuracy: 0.6755 - val_loss: 0.6299\n",
      "Epoch 2/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 55ms/step - accuracy: 0.6629 - loss: 0.6256 - val_accuracy: 0.7125 - val_loss: 0.5793\n",
      "Epoch 3/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 55ms/step - accuracy: 0.6995 - loss: 0.5751 - val_accuracy: 0.7180 - val_loss: 0.5713\n",
      "Epoch 4/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 55ms/step - accuracy: 0.7223 - loss: 0.5342 - val_accuracy: 0.7240 - val_loss: 0.5505\n",
      "Epoch 5/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 55ms/step - accuracy: 0.7431 - loss: 0.5196 - val_accuracy: 0.7320 - val_loss: 0.5602\n",
      "Epoch 6/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 56ms/step - accuracy: 0.7572 - loss: 0.4975 - val_accuracy: 0.7435 - val_loss: 0.5351\n",
      "Epoch 7/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 56ms/step - accuracy: 0.7642 - loss: 0.4832 - val_accuracy: 0.7505 - val_loss: 0.5202\n",
      "Epoch 8/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 59ms/step - accuracy: 0.7841 - loss: 0.4642 - val_accuracy: 0.7810 - val_loss: 0.4808\n",
      "Epoch 9/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 67ms/step - accuracy: 0.7876 - loss: 0.4490 - val_accuracy: 0.7365 - val_loss: 0.5543\n",
      "Epoch 10/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 138ms/step - accuracy: 0.7956 - loss: 0.4341 - val_accuracy: 0.7655 - val_loss: 0.5220\n",
      "Epoch 11/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 118ms/step - accuracy: 0.7966 - loss: 0.4321 - val_accuracy: 0.7895 - val_loss: 0.4750\n",
      "Epoch 12/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 119ms/step - accuracy: 0.8088 - loss: 0.4106 - val_accuracy: 0.7825 - val_loss: 0.4966\n",
      "Epoch 13/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 115ms/step - accuracy: 0.8072 - loss: 0.4143 - val_accuracy: 0.7900 - val_loss: 0.4811\n",
      "Epoch 14/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 129ms/step - accuracy: 0.8127 - loss: 0.4025 - val_accuracy: 0.7715 - val_loss: 0.5122\n",
      "Epoch 15/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 140ms/step - accuracy: 0.8229 - loss: 0.3981 - val_accuracy: 0.7955 - val_loss: 0.4815\n",
      "Epoch 16/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 102ms/step - accuracy: 0.8303 - loss: 0.3738 - val_accuracy: 0.8105 - val_loss: 0.4366\n",
      "Epoch 17/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 85ms/step - accuracy: 0.8453 - loss: 0.3612 - val_accuracy: 0.7975 - val_loss: 0.4973\n",
      "Epoch 18/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 81ms/step - accuracy: 0.8455 - loss: 0.3472 - val_accuracy: 0.8080 - val_loss: 0.4632\n",
      "Epoch 19/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 84ms/step - accuracy: 0.8558 - loss: 0.3386 - val_accuracy: 0.7735 - val_loss: 0.4972\n",
      "Epoch 20/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 93ms/step - accuracy: 0.8452 - loss: 0.3430 - val_accuracy: 0.8135 - val_loss: 0.4496\n",
      "Epoch 21/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 89ms/step - accuracy: 0.8535 - loss: 0.3278 - val_accuracy: 0.8125 - val_loss: 0.4533\n",
      "Epoch 22/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 82ms/step - accuracy: 0.8671 - loss: 0.3149 - val_accuracy: 0.8050 - val_loss: 0.4765\n",
      "Epoch 23/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 79ms/step - accuracy: 0.8548 - loss: 0.3211 - val_accuracy: 0.8000 - val_loss: 0.4657\n",
      "Epoch 24/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 77ms/step - accuracy: 0.8709 - loss: 0.2972 - val_accuracy: 0.7970 - val_loss: 0.5149\n",
      "Epoch 25/25\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 68ms/step - accuracy: 0.8716 - loss: 0.2954 - val_accuracy: 0.8140 - val_loss: 0.4908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1de7d5b2600>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsSiWEJY1BPB",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:28:59.417916Z",
     "start_time": "2024-09-06T19:28:59.341080Z"
    }
   },
   "source": [
    "def make_prediction(path: str, target_size = (64, 64)) -> str:\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    \n",
    "    test_image = image.load_img(path, target_size=target_size)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    \n",
    "    return 'dog' if result[0][0] == 1 else 'cat'\n",
    "\n",
    "image_path = 'dataset/single_prediction/cat_or_dog_1.jpg'\n",
    "prediction = make_prediction(image_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED9KB3I54c1i",
    "ExecuteTime": {
     "end_time": "2024-09-06T19:29:00.734125Z",
     "start_time": "2024-09-06T19:29:00.723723Z"
    }
   },
   "source": [
    "print(prediction)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Problem 2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T19:29:19.042792Z",
     "start_time": "2024-09-06T19:29:18.961008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = 'dataset/single_prediction/cat_or_dog_2.jpg'\n",
    "prediction = make_prediction(image_path)\n",
    "print(prediction)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "cat\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Problem 2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T20:11:23.909996Z",
     "start_time": "2024-09-06T20:11:21.800124Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install colorama",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\src\\my\\uwf-idc6146-deep-learning\\lib\\site-packages (0.4.6)\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T20:11:25.564354Z",
     "start_time": "2024-09-06T20:11:25.557764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_files_by_extension(folder_path:str, file_extension:str) -> list[str]:\n",
    "    from pathlib import Path\n",
    "    path = Path(folder_path)\n",
    "    return [str(file) for file in path.glob(f'*{file_extension}')]\n",
    "    \n",
    "def get_random_file(files:list[str]) -> str:\n",
    "    import random\n",
    "    index = random.randint(0, len(files) - 1)\n",
    "    return files[index]\n",
    "\n",
    "def try_predict_animal_from_file(file_path: str):\n",
    "    from colorama import Fore, Style\n",
    "    \n",
    "    actual = 'cat' if 'cat' in file_path else 'dog'\n",
    "    prediction = make_prediction(file_path)\n",
    "    color = Fore.GREEN if prediction == actual else Fore.RED\n",
    "    \n",
    "    print(f\"{color}File: {file_path}; Prediction: {prediction}; Actual: {actual}{Style.RESET_ALL}\")\n",
    "    \n",
    "def try_predict_animals_from_files(files, iterations=10):\n",
    "    for iteration in range(iterations):\n",
    "        random_file = get_random_file(files)\n",
    "        try_predict_animal_from_file(random_file)\n"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try to predict cats"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T20:11:49.949083Z",
     "start_time": "2024-09-06T20:11:49.468357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_extension = '.jpg'\n",
    "root_path = 'dataset/test_set/cats'\n",
    "files = get_files_by_extension(root_path, file_extension)\n",
    "\n",
    "try_predict_animals_from_files(files)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\cats\\cat.4074.jpg; Prediction: cat; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step\n",
      "\u001B[31mFile: dataset\\test_set\\cats\\cat.4804.jpg; Prediction: dog; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\cats\\cat.4720.jpg; Prediction: cat; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\cats\\cat.4025.jpg; Prediction: cat; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[31mFile: dataset\\test_set\\cats\\cat.4269.jpg; Prediction: dog; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[31mFile: dataset\\test_set\\cats\\cat.4706.jpg; Prediction: dog; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[31mFile: dataset\\test_set\\cats\\cat.4643.jpg; Prediction: dog; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "\u001B[31mFile: dataset\\test_set\\cats\\cat.4715.jpg; Prediction: dog; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\cats\\cat.4032.jpg; Prediction: cat; Actual: cat\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[31mFile: dataset\\test_set\\cats\\cat.4298.jpg; Prediction: dog; Actual: cat\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try to predict dogs"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T20:11:52.648038Z",
     "start_time": "2024-09-06T20:11:52.135923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root_path = 'dataset/test_set/dogs'\n",
    "files = get_files_by_extension(root_path, file_extension)\n",
    "\n",
    "try_predict_animals_from_files(files)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4140.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4132.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4995.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4186.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4960.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4259.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4063.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4259.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4097.jpg; Prediction: dog; Actual: dog\u001B[0m\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[32mFile: dataset\\test_set\\dogs\\dog.4928.jpg; Prediction: dog; Actual: dog\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
